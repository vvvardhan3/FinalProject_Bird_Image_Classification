{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Base path to the dataset\n",
        "base_path = '/content/drive/MyDrive/CubDatset'\n",
        "\n",
        "# Paths to the required files and directories\n",
        "images_file = os.path.join(base_path, 'images.txt')\n",
        "image_dir = os.path.join(base_path, 'images')\n",
        "\n",
        "# Create directories for training and testing images\n",
        "train_dir = os.path.join(base_path, 'train')\n",
        "test_dir = os.path.join(base_path, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Create a dictionary mapping from class name to a list of image filenames\n",
        "class_to_images = {}\n",
        "with open(images_file, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        image_id, image_filename = line.strip().split()\n",
        "        class_name = image_filename.split('/')[0]\n",
        "        if class_name not in class_to_images:\n",
        "            class_to_images[class_name] = []\n",
        "        class_to_images[class_name].append(image_filename)\n",
        "\n",
        "# Limit the number of images per class to 5\n",
        "for class_name in class_to_images:\n",
        "    class_to_images[class_name] = class_to_images[class_name][:5]  # Keep only the first 5 images\n",
        "\n",
        "# Split each class's images into 80% training and 20% testing, and copy them to their respective directories\n",
        "for class_name, images in class_to_images.items():\n",
        "    # Here, since we have 5 images, the split will typically be 4 training and 1 testing\n",
        "    # Shuffle and split\n",
        "    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Function to copy images to the target directory\n",
        "    def copy_images(images, target_dir):\n",
        "        class_dir = os.path.join(target_dir, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        for image_filename in images:\n",
        "            source_path = os.path.join(image_dir, image_filename)\n",
        "            if os.path.exists(source_path):\n",
        "                shutil.copy(source_path, os.path.join(class_dir, image_filename.split('/')[1]))\n",
        "            else:\n",
        "                print(f\"Image {image_filename} not found in subset.\")\n",
        "\n",
        "    # Copy training and testing images\n",
        "    copy_images(train_images, train_dir)\n",
        "    copy_images(test_images, test_dir)\n",
        "\n",
        "print(\"Dataset splitting into 80:20 complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpIOZFvXM2OT",
        "outputId": "f62fb6ea-d439-428b-a34b-bd0f02f8b3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splitting into 80:20 complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ruc1lileOYA2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}