{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ieIpxN8Yc7Dy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNKKJ2ZCysKh",
    "outputId": "4a800259-cc5a-4a4e-d038-d351574725cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Found 2400 images belonging to 200 classes.\n",
      "Found 599 images belonging to 200 classes.\n",
      "Epoch 1/50\n",
      "75/75 [==============================] - 1323s 17s/step - loss: 9.3846 - accuracy: 0.0017\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 1302s 17s/step - loss: 5.4636 - accuracy: 0.0146\n",
      "Epoch 3/50\n",
      "41/75 [===============>..............] - ETA: 9:46 - loss: 5.3374 - accuracy: 0.0198 "
     ]
    }
   ],
   "source": [
    "# Load the base VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Data generator for train and test data\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Directories for training and testing data\n",
    "train_dir = '/content/drive/MyDrive/15ImagesinEachClass/train'\n",
    "test_dir = '/content/drive/MyDrive/15ImagesinEachClass/test'\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Create the classifier model\n",
    "model = Sequential()\n",
    "model.add(base_model)  # Add the VGG16 base model\n",
    "model.add(Flatten())   # Flatten the output of the base model\n",
    "model.add(Dense(256, activation='relu'))  # Add a fully connected layer\n",
    "model.add(Dropout(0.5))  # Add dropout for regularization\n",
    "model.add(Dense(200, activation='softmax'))  # Final classification layer\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYh-aygTiY_p"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred, axis=1)  # Get the index of the max value\n",
    "\n",
    "# Get the true labels for the test set\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Calculate the confusion matrix and classification report\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nn1JRY9UiqF3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPqP7tqUy_xF"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_dir = '/content/drive/MyDrive/15ImagesinEachClass/train'\n",
    "test_dir =  '/content/drive/MyDrive/15ImagesinEachClass/test'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "# feature_extractor = Model(inputs=model.input, outputs=model.get_layer('dense_1').output)\n",
    "\n",
    "# Extract features from the train and test data\n",
    "train_features = feature_extractor.predict(train_generator)\n",
    "test_features = feature_extractor.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "039-s29DzAQj"
   },
   "outputs": [],
   "source": [
    "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
    "test_features_flat = test_features.reshape(test_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eOf2WpEzFBN"
   },
   "outputs": [],
   "source": [
    "train_features_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jv3yJHS_Flzx"
   },
   "outputs": [],
   "source": [
    "test_features_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSJcYg5Sz2dQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "# from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xce-7TjLzG4i"
   },
   "outputs": [],
   "source": [
    "# n_components = 32\n",
    "\n",
    "# # Apply PCA\n",
    "# pca = PCA(n_components=n_components)\n",
    "# train_features_reshaped = pca.fit_transform(train_features_flat)\n",
    "\n",
    "# # # Sparse PCA\n",
    "# # sparse_pca = SparsePCA(n_components=n_components, alpha=10)\n",
    "# # train_features_reshaped = sparse_pca.fit_transform(train_features_flat)\n",
    "\n",
    "# # tsne = TSNE(n_components = n_components)\n",
    "# # train_features_reshaped = tsne.fit_transform(train_features_flat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZtjgQz6zrKb"
   },
   "outputs": [],
   "source": [
    "# n_components = 32\n",
    "\n",
    "# # Apply PCA\n",
    "# pca = PCA(n_components=n_components)\n",
    "# test_features_reshaped = pca.fit_transform(test_features_flat)\n",
    "\n",
    "# # sparse_pca = SparsePCA(n_components=n_components, alpha=10)\n",
    "# # test_features_reshaped = sparse_pca.fit_transform(test_features_flat)\n",
    "\n",
    "# # tsne = TSNE(n_components = n_components)\n",
    "# # test_features_reshaped = tsne.fit_transform(test_features_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJXxn18tz4Ls"
   },
   "outputs": [],
   "source": [
    "# train_features_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgxTHgHbHA4_"
   },
   "outputs": [],
   "source": [
    "# test_features_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsCXvChsz6n7"
   },
   "outputs": [],
   "source": [
    "# ANN\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_features.shape[1]))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=train_features_flat.shape[1]),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(200, activation='softmax')\n",
    "])\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "train_labels = to_categorical(train_generator.labels, num_classes=200)\n",
    "test_labels = to_categorical(test_generator.labels, num_classes=200)\n",
    "\n",
    "# Train the model on the extracted features\n",
    "model.fit(train_features_flat, train_labels, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOWkA-ST0FGg"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_features_flat)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_true = test_generator.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "#model.save(\"/content/drive/My Drive/OCR/Stimulation/ANN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wf5s8YLF0cT-"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_labels_rf = train_generator.labels\n",
    "test_labels_rf = test_generator.labels\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(train_features_flat, train_labels_rf)\n",
    "\n",
    "y_pred = rf_classifier.predict(test_features_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PQaIU9G6BTy"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels_rf, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generate and print a classification report\n",
    "report = classification_report(test_labels_rf, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Generate and print a confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels_rf, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MxzO6FN3klR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxUJb5S_e9aL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
