{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1qQZAVqvttTJVCxW9upyBV_Xf8ibSZQCA","authorship_tag":"ABX9TyNMnziHk9bfvnT0xxx9myrs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQ5CgKfCgluj","executionInfo":{"status":"ok","timestamp":1710229542995,"user_tz":240,"elapsed":198657,"user":{"displayName":"Vishnu Vardhan Vankayalapati","userId":"08231567426981726494"}},"outputId":"e90fc89b-30b6-425e-ce6d-bdcd02d0b3de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 96 images belonging to 2 classes.\n","Found 24 images belonging to 2 classes.\n","Epoch 1/5\n","3/3 [==============================] - 43s 11s/step - loss: 2.3540 - accuracy: 0.5833 - val_loss: 2.7696 - val_accuracy: 0.5000\n","Epoch 2/5\n","3/3 [==============================] - 35s 12s/step - loss: 1.5772 - accuracy: 0.5625 - val_loss: 175.1883 - val_accuracy: 0.5000\n","Epoch 3/5\n","3/3 [==============================] - 32s 10s/step - loss: 0.7575 - accuracy: 0.5938 - val_loss: 743.6985 - val_accuracy: 0.5000\n","Epoch 4/5\n","3/3 [==============================] - 32s 10s/step - loss: 0.6343 - accuracy: 0.6250 - val_loss: 909.2357 - val_accuracy: 0.5000\n","Epoch 5/5\n","3/3 [==============================] - 31s 10s/step - loss: 0.5806 - accuracy: 0.6771 - val_loss: 773.2150 - val_accuracy: 0.5000\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define custom ResNet block\n","def resnet_block(x, filters, kernel_size=3, strides=(1, 1), activation='relu'):\n","    y = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n","    y = layers.BatchNormalization()(y)\n","    y = layers.Activation(activation)(y)\n","\n","    y = layers.Conv2D(filters, kernel_size, padding='same')(y)\n","    y = layers.BatchNormalization()(y)\n","\n","    if strides != (1, 1):\n","        # Downsample x to match the shape of y\n","        x = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n","        x = layers.BatchNormalization()(x)\n","\n","    # Add x and y\n","    y = layers.Add()([x, y])\n","    y = layers.Activation(activation)(y)\n","    return y\n","\n","# Define custom ResNet50 model\n","def custom_resnet50(input_shape=(224, 224, 3), num_classes=2):\n","    input_tensor = layers.Input(shape=input_shape)\n","\n","    # Initial Convolutional Block\n","    x = layers.Conv2D(64, 7, strides=2, padding='same')(input_tensor)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation('relu')(x)\n","    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n","\n","    # Residual Blocks\n","    x = resnet_block(x, filters=64, strides=(1, 1))\n","    x = resnet_block(x, filters=64)\n","\n","    x = resnet_block(x, filters=128, strides=(2, 2))\n","    x = resnet_block(x, filters=128)\n","\n","    x = resnet_block(x, filters=256, strides=(2, 2))\n","    x = resnet_block(x, filters=256)\n","\n","    x = resnet_block(x, filters=512, strides=(2, 2))\n","    x = resnet_block(x, filters=512)\n","\n","    # Average Pooling and Fully Connected Layer\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    # Create model\n","    model = Model(input_tensor, x, name='custom_resnet50')\n","    return model\n","\n","# Instantiate the custom ResNet50 model\n","model = custom_resnet50()\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Display model architecture\n","# model.summary()\n","\n","# Paths to your train and test directories\n","train_dir = '/content/drive/MyDrive/2Classes/train'\n","test_dir = '/content/drive/MyDrive/2Classes/test'\n","\n","# Image dimensions\n","img_height, img_width = 224, 224\n","batch_size = 32\n","\n","# Create data generators\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","# Train the model\n","history = model.fit(train_generator,\n","                    steps_per_epoch=len(train_generator),\n","                    epochs=5,\n","                    validation_data=validation_generator,\n","                    validation_steps=len(validation_generator))"]},{"cell_type":"code","source":["# Extract training and validation accuracy from history\n","training_accuracy = (history.history['accuracy'][-1] * 100)\n","validation_accuracy = (history.history['val_accuracy'][-1] * 100)\n","\n","print(f\"Training Accuracy: {training_accuracy}\")\n","print(f\"Validation Accuracy: {validation_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7Ichspfg-nr","executionInfo":{"status":"ok","timestamp":1710229542995,"user_tz":240,"elapsed":7,"user":{"displayName":"Vishnu Vardhan Vankayalapati","userId":"08231567426981726494"}},"outputId":"0285b246-5512-447f-858f-1e727ec0912e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Accuracy: 67.70833134651184\n","Validation Accuracy: 50.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_qKKy8Nfisl6","executionInfo":{"status":"ok","timestamp":1710229542995,"user_tz":240,"elapsed":4,"user":{"displayName":"Vishnu Vardhan Vankayalapati","userId":"08231567426981726494"}}},"execution_count":12,"outputs":[]}]}